# Example environment variables for openai-proxy

# Port for the proxy to listen on (default: 2020)
# PORT=2020

# Socket path for HAProxy stats (default: /tmp/haproxy-openai-proxy.sock)
# SOCKET=/tmp/haproxy-openai-proxy.sock

# Backend endpoints for routing
# Define environment variables that map API paths to backend URLs.
# The variable name is composed of OPENAI_PROXY_BACKEND_ followed by the API path in uppercase, with slashes replaced by underscores.

# Example: Map /v1/audio/speech to a local backend running Kokoro-FastAPI
BACKEND_AUDIO_SPEECH=http://studio:8880

# Example: Map /v1/audio/transcriptions to a local backend running Whisper.cpp
BACKEND_AUDIO_TRANSCRIPTIONS=https://api.ailocal.org

# Example: Map /v1/chat/completions to a local backend running Ollama
BACKEND_CHAT_COMPLETIONS=http://studio:11434

# Example: Map /v1/completions to a local backend running Ollama
# BACKEND_COMPLETIONS=https://api.openai.com

# Default backend for any unmapped paths (default: https://api.openai.com:443)
BACKEND_DEFAULT=https://openrouter.ai/api/v1
# BACKEND_DEFAULT=https://api.openai.com

# Path to custom error page (optional)
# ERROR_PAGE=$(dirname "$0")/haproxy/errors/503.http
