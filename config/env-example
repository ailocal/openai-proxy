# Example environment variables for openai-proxy

# Port for the proxy to listen on (default: 2020)
# PORT=2020

# Socket path for HAProxy stats (default: /tmp/haproxy-openai-proxy.sock)
# SOCKET=/tmp/haproxy-openai-proxy.sock

# Backend endpoints for routing
# Define environment variables that map API paths to backend URLs.
# The variable name is composed of BACKEND_ followed by the API path in uppercase, with slashes replaced by underscores.

# Example: Map /v1/audio/speech to a local backend running Kokoro-FastAPI
# BACKEND_AUDIO_SPEECH=http://localhost:8880

# Example: Map /v1/audio/transcriptions to a local backend running Whisper.cpp
# BACKEND_AUDIO_TRANSCRIPTIONS=http://localhost:2022

# Example: Map /v1/chat/completions to a local backend running Ollama
# BACKEND_CHAT_COMPLETIONS=http://localhost:11434

# Example: Map /v1/completions to a local backend running Ollama
# BACKEND_COMPLETIONS=http://localhost:11434

# Default backend for any unmapped paths (default: https://api.openai.com:443)
# BACKEND_DEFAULT=https://api.openai.com:443

# Path to custom error page (optional)
# ERROR_PAGE=$(dirname "$0")/haproxy/errors/503.http
